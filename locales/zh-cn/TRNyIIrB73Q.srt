1
00:00:00,000 --> 00:00:06,000
这个问题里 你被要求限制网页蜘蛛搜寻的深度 (depth)

2
00:00:06,000 --> 00:00:11,000
为了了解这个问题 我们需要做的是

3
00:00:11,000 --> 00:00:19,000
划一个连结 (link) 图 我要从种子页面 A 开始

4
00:00:19,000 --> 00:00:29,000
从 A 开始 我有 link 到页面 B 和页面 C

5
00:00:29,000 --> 00:00:35,000
现在 B 连到了 D C 连到了 E

6
00:00:35,000 --> 00:00:41,000
现在 只为了让事情有点棘手 E 连到了 D

7
00:00:41,000 --> 00:00:45,000
最后 D 连到了 F

8
00:00:45,000 --> 00:00:47,000
实际上我们需要做什么呢？

9
00:00:47,000 --> 00:00:55,000
我们需要追踪还未爬行的网页 就像之前一样

10
00:00:55,000 --> 00:00:58,000
我们需要记录我们已爬行过的网页

11
00:00:58,000 --> 00:01:02,000
因为一旦我们爬行过这些网页 我们真的不想再爬行一次

12
00:01:02,000 --> 00:01:10,000
我要介绍一个新列表 记录网页下一步的深度

13
00:01:10,000 --> 00:01:14,000
我称它为 next-depth

14
00:01:14,000 --> 00:01:19,000
我们从 tocrawl 开始 我们只有种子页面

15
00:01:19,000 --> 00:01:23,000
现在 我们尚未爬行任何东西 也不知道什么将会出现

16
00:01:23,000 --> 00:01:29,000
我们从只有种子页面的 tocrawl 开始

17
00:01:29,000 --> 00:01:37,000
现在 从那里我们看到 A 我们看到 A 连结到两个网页

18
00:01:37,000 --> 00:01:45,000
我们在 A next-depth 是页面 B 和 C  深度是 1

19
00:01:45,000 --> 00:01:51,000
我们实际上是要将 A 从 tocrawl 移动到 crawled

20
00:01:51,000 --> 00:01:53,000
因为我们正看着它

21
00:01:53,000 --> 00:02:00,000
我们看到 接下来的页面是 C 和 B

22
00:02:00,000 --> 00:02:07,000
这些是我们下一次要爬行的页面  我要把这些放到 tocrawl

23
00:02:07,000 --> 00:02:10,000
我们来看看这些下一回要抓的网页

24
00:02:10,000 --> 00:02:19,000
如果我们看 B  B 有一个邻居 D 然后 C 有一个邻居 E

25
00:02:19,000 --> 00:02:24,000
我们执行了好几个步骤 只为了了解程序码是如何运作的

26
00:02:24,000 --> 00:02:29,000
我只是看看每一个深度 (depth) 里有什么

27
00:02:29,000 --> 00:02:37,000
我们现在已爬行过 B 和 C 所以这两个移到 crawled

28
00:02:37,000 --> 00:02:42,000
目前在下一个深度有 D 和 E 所以这些是我们想看的

29
00:02:42,000 --> 00:02:45,000
我们要把 D 和 E 移到这里

30
00:02:45,000 --> 00:02:50,000
然后我们要看看 D 和 E 接下来的页面

31
00:02:50,000 --> 00:02:58,000
D 有邻居 F E 有邻居 D 这些在深度 3

32
00:02:58,000 --> 00:03:03,000
现在 我们不希望在这里加 D  因为实际上我们已经看过 D 了

33
00:03:03,000 --> 00:03:08,000
但我们将会看到 写真正的程序码时 要如何处理它

34
00:03:08,000 --> 00:03:15,000
现在 我们把 D 和 E 放到 crawled

35
00:03:15,000 --> 00:03:19,000
然后 在这里得到 F 和 D

36
00:03:19,000 --> 00:03:24,000
我们可以继续 取决于我们想达到的深度

37
00:03:24,000 --> 00:03:27,000
这是程序码如何运作的想法

38
00:03:27,000 --> 00:03:30,000
我们将从一个页面开始

39
00:03:30,000 --> 00:03:34,000
我们要爬行它 以及在同一深度的其他网页

40
00:03:34,000 --> 00:03:41,000
然后将这些页面加到 next-depth 并且替换周围的列表

41
00:03:41,000 --> 00:03:44,000
希望你在程序码中可以更清楚地了解

42
00:03:44,000 --> 00:03:51,000
这是提供的程序码 crawl-web 我们要做一点改变

43
00:03:51,000 --> 00:03:56,000
若要考虑深度 首先该做什么呢？

44
00:03:56,000 --> 00:03:59,000
嗯 我们需要另一个列表 next-depth

45
00:03:59,000 --> 00:04:05,000
它会记录下一级的 links

46
00:04:05,000 --> 00:04:10,000
当我们从 depth 0 开始

47
00:04:10,000 --> 00:04:15,000
当 tocrawl 里有 link 时 我们将继续执行 while loop

48
00:04:15,000 --> 00:04:18,000
因为如果没有可爬行的网页 我们无法进行下去

49
00:04:18,000 --> 00:04:27,000
此外 当我们的 depth 不大于 max-depth  也就是程序的输入值

50
00:04:27,000 --> 00:04:32,000
和以前一样 我们会从 tocrawl 移出最后一个元素

51
00:04:32,000 --> 00:04:37,000
我们不会对这一行做任何的更改

52
00:04:37,000 --> 00:04:42,000
但是并不加到 tocrawl 里 因为我们不想要弄乱

53
00:04:42,000 --> 00:04:48,000
目前正在搜寻的页面与下一级的页面

54
00:04:48,000 --> 00:04:53,000
我们实际上要加入新的 link 到 next-depth

55
00:04:53,000 --> 00:04:59,000
然后像以前一样  我们要加入已爬行过的页面到列表 crawled

56
00:04:59,000 --> 00:05:02,000
这样就知道我们已经看过了

57
00:05:02,000 --> 00:05:04,000
我们未来不打算再看一次

58
00:05:04,000 --> 00:05:08,000
现在 我们需要加入的最后程序码

59
00:05:08,000 --> 00:05:12,000
当我们已经完成在某一级的所有列表后

60
00:05:12,000 --> 00:05:15,000
如同我向你展示的例子

61
00:05:15,000 --> 00:05:21,000
我们会把 tocrawl 以及 next-depth 做交换

62
00:05:21,000 --> 00:05:25,000
所以 tocrawl 现在是空的

63
00:05:25,000 --> 00:05:32,000
next-depth 包含了所有的新 link   我要使用多指定 (multiple assignment)

64
00:05:32,000 --> 00:05:37,000
来交换 tocrawl 和 next-depth

65
00:05:37,000 --> 00:05:42,000
tocrawl 等于 next-depth next-depth 又变成空的

66
00:05:42,000 --> 00:05:49,000
这样 我们就能以干净的列表再次执行 while loop

67
00:05:49,000 --> 00:05:53,000
我们增加深度 1

68
00:05:53,000 --> 00:05:55,000
传回 crawled

69
00:05:55,000 --> 00:06:03,000
只是很快地回顾一下 只要我们有一些页面可爬行

70
00:06:03,000 --> 00:06:08,000
而且 depth 小于或等于 max-depth  我们会继续进行 while loop

71
00:06:08,000 --> 00:06:12,000
我们采取页面 如果之前尚未爬行这个页面

72
00:06:12,000 --> 00:06:16,000
我们将页面的所有 link 加入 next-depth

73
00:06:16,000 --> 00:06:22,000
然后我们采取网页 把它放在 crawled 列表

74
00:06:22,000 --> 00:06:26,000
我们一直这样做 如果没有任何网页需要爬行  就把他们做交换

75
00:06:26,000 --> 00:06:31,000
但是 如果我们有网页需要爬行  我们继续进行 while loop

76
00:06:31,000 --> 00:06:34,000
直到 tocrawl 是空的

77
00:06:34,000 --> 00:06:39,000
一旦 tocrawl 是空的 这意谓着这一级已经完成  这个深度已完成

78
00:06:39,000 --> 00:06:42,000
我们要去继续启动下一个深度 就是这样


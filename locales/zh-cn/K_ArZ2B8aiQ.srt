1
00:00:00,000 --> 00:00:04,000
现在我们可以回到这个问题上来 

2
00:00:04,000 --> 00:00:06,000
那就是提取包含一个网页中所有链接的列表

3
00:00:06,000 --> 00:00:10,000
这是创建网络爬虫的第一步 它将抓取一个网页的集合 

4
00:00:10,000 --> 00:00:13,000
找到一个种子页面上所有的链接

5
00:00:13,000 --> 00:00:16,000
我们将从一个网页开始

6
00:00:16,000 --> 00:00:19,000
我们有某种子页面的 url

7
00:00:19,000 --> 00:00:24,000
我们用 get_page 过程来获取一个字符串 即这个页面的文本

8
00:00:24,000 --> 00:00:26,000
这里面有很多内容都与我们不相干 

9
00:00:26,000 --> 00:00:29,000
但里面也包括了一些超级链接 

10
00:00:29,000 --> 00:00:33,000
这些超级链接也包含了通往这个页面的链接的 url

11
00:00:33,000 --> 00:00:36,000
我们的目标是定义一个过程 我们称之为 get_all_links

12
00:00:36,000 --> 00:00:41,000
这个过程的输入是代表一个网页上文本的字符串 

13
00:00:41,000 --> 99:59:59,000
并生成一个包含这个页面所链接的所有 url 的列表 以此作为输出

